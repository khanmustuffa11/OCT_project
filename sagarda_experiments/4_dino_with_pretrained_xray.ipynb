{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed592d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(no):\n",
    "    torch.manual_seed(no)\n",
    "    random.seed(no)\n",
    "    np.random.seed(no)\n",
    "    os.environ['PYTHONHASHSEED'] = str()\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c694fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d65701",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"OCT_final_train_csv.csv\")\n",
    "val = pd.read_csv(\"OCT_final_val_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c82150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train.source==\"oct_mendely\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa41ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb99beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetLabeled(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, split, images_folder, transform = None):\n",
    "        self.df = df\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.split=split\n",
    "        #self.class2index = {\"cat\":0, \"dog\":1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.loc[index][\"path\"]\n",
    "        label = self.df.loc[index][\"level\"]\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        image = image.convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.split==\"unlabeled\":\n",
    "            return image, -1\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539603be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDatasetLabeled(df=train, split=\"train\",  images_folder=\"./\", transform=data_transforms['train'])\n",
    "val_data = CustomDatasetLabeled(df=val, split=\"val\", images_folder=\"./\", transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.ConcatDataset([train_data, val_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b60aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[0][0].shape\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, \n",
    "#                                           num_workers=8)\n",
    "# val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False, num_workers=8)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=80, shuffle=True, \n",
    "                                           num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30088b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoVisionTransformerClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DinoVisionTransformerClassifier, self).__init__()\n",
    "        self.transformer = dinov2_vits14\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = self.transformer.norm(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinoVisionTransformerClassifier()\n",
    "model.load_state_dict(torch.load(\"./models/x_ray_pretrain_dino_10_epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "   param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=384, out_features=256, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=256, \n",
    "              out_features=8,\n",
    "              bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.parameters():\n",
    "#    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f09a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e019017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d10af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ce270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
    "                 exist_ok=True # if models directory already exists, don't error\n",
    ")\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"torch_dino_finetuned_with_valid_data_merged_5_epoch.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754d984",
   "metadata": {},
   "source": [
    "# Dino Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b31472",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"OCT_final_testwcsv.csv\")\n",
    "test['level'] = test['label']\n",
    "test.drop(\"label\", axis=1, inplace=True)\n",
    "test_data = CustomDatasetLabeled(df=test, split=\"test\", images_folder=\"./\", transform=data_transforms['test'])\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83585619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test[test.path!=\"data/oct/test/0/*\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa516750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[test.level==1]\n",
    "test.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4450ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.to(\"cpu\") == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_loader)} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb98e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with trained model\n",
    "y_preds = []\n",
    "labels = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "  for X, y in tqdm(test_loader, desc=\"Making predictions\"):\n",
    "    # Send data and targets to target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # Do the forward pass\n",
    "    y_logit = model(X)\n",
    "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "    # Put predictions on CPU for evaluation\n",
    "    y_preds.append(y_pred.cpu())\n",
    "    labels.append(y)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "label_tensor = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51473eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b746b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(label_tensor.cpu(), y_pred_tensor.cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,\n",
    "                             display_labels=class_names)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36608e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(precision_score(y_pred_tensor.cpu(), label_tensor.cpu(), average=\"weighted\"))\n",
    "print(recall_score(y_pred_tensor.cpu(), label_tensor.cpu(), average=\"weighted\"))\n",
    "print(f1_score(y_pred_tensor.cpu(), label_tensor.cpu(), average=\"weighted\"))\n",
    "print(accuracy_score(y_pred_tensor.cpu(), label_tensor.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73609cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cf_matrix.sum(axis=0) - np.diag(cf_matrix) \n",
    "FN = cf_matrix.sum(axis=1) - np.diag(cf_matrix)\n",
    "TP = np.diag(cf_matrix)\n",
    "TN = cf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "print(\"Sensitivity: {}\".format(TPR))\n",
    "print(\"Specificity: {}\".format(TNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49429d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca3e2e1",
   "metadata": {},
   "source": [
    "# Testing Pretrained Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad44930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model1 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model1.fc.in_features\n",
    "model1.fc = nn.Linear(num_ftrs, 8)\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfddafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model1(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.to(\"cpu\") == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(val_loader)} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc28ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artelus",
   "language": "python",
   "name": "artelus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
